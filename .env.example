# Wolf AI Assistant Environment Configuration

# Ollama Configuration
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Alternative models you can use after downloading:
# OLLAMA_MODEL=mistral
# OLLAMA_MODEL=codellama
# OLLAMA_MODEL=orca-mini
# OLLAMA_MODEL=dolphin-mistral

# For remote Ollama instance:
# OLLAMA_URL=http://your-server-ip:11434

# Database Configuration
DATABASE_PATH=./data/wolf_ai.db

# Security Settings
REQUIRE_CONFIRMATION_FOR_SYSTEM_COMMANDS=true

# Audio Settings (for environments with audio hardware)
ENABLE_TTS=true
ENABLE_VOICE_INPUT=true